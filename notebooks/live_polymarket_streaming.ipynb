{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Polymarket Trading Data Streaming and Visualization\n",
    "\n",
    "This notebook streams live data from the polymarket_trades.csv file as it's being written to by another service, and displays it in a stacked bar chart with line overlay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from collections import deque\n",
    "import time\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from IPython.display import display, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Allow nested asyncio in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Enable interactive plots\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to monitor\n",
    "CSV_FILE_PATH = '/home/jonathanmines/Documents/code/signal_drift_project/SignalDrift/data/polymarket_trades.csv'\n",
    "\n",
    "# Visualization settings\n",
    "WINDOW_SIZE = 50  # Number of time points to display\n",
    "UPDATE_INTERVAL = 1000  # Milliseconds between updates\n",
    "TIME_WINDOW = 60  # Seconds of data to show\n",
    "\n",
    "# Asset configuration (based on the two asset IDs in the data)\n",
    "ASSET_NAMES = {\n",
    "    '5899348323059455657630528606815138588415095483052205208567031442326527433126': 'Asset A',\n",
    "    '76440473074388722537799893602404687230922238288182630419521127770642474448937': 'Asset B'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV File Monitor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVFileMonitor:\n",
    "    \"\"\"Monitor a CSV file for new data and stream updates\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, check_interval=0.5):\n",
    "        self.file_path = file_path\n",
    "        self.check_interval = check_interval\n",
    "        self.last_position = 0\n",
    "        self.last_size = 0\n",
    "        \n",
    "    def get_new_data(self):\n",
    "        \"\"\"Read new data from the CSV file since last check\"\"\"\n",
    "        try:\n",
    "            # Check if file exists\n",
    "            if not os.path.exists(self.file_path):\n",
    "                return None\n",
    "            \n",
    "            # Get current file size\n",
    "            current_size = os.path.getsize(self.file_path)\n",
    "            \n",
    "            # If file hasn't grown, no new data\n",
    "            if current_size <= self.last_size:\n",
    "                return None\n",
    "            \n",
    "            # Read the entire file to get new rows\n",
    "            df = pd.read_csv(self.file_path)\n",
    "            \n",
    "            # Get only new rows\n",
    "            if self.last_position < len(df):\n",
    "                new_data = df.iloc[self.last_position:].copy()\n",
    "                self.last_position = len(df)\n",
    "                self.last_size = current_size\n",
    "                return new_data\n",
    "            \n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        \"\"\"Get all data from the CSV file\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(self.file_path):\n",
    "                df = pd.read_csv(self.file_path)\n",
    "                self.last_position = len(df)\n",
    "                self.last_size = os.path.getsize(self.file_path)\n",
    "                return df\n",
    "            return pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file: {e}\")\n",
    "            return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trade_data(df):\n",
    "    \"\"\"Process raw trade data for visualization\"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Clean column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    \n",
    "    # Map asset IDs to names\n",
    "    df['asset_name'] = df['asset_id'].map(ASSET_NAMES)\n",
    "    \n",
    "    # Aggregate by time window (e.g., 1 second)\n",
    "    df['time_bin'] = df['datetime'].dt.floor('1s')\n",
    "    \n",
    "    # Group by time and asset to get average prices\n",
    "    grouped = df.groupby(['time_bin', 'asset_name']).agg({\n",
    "        'price': 'mean',\n",
    "        'size': 'sum',\n",
    "        'timestamp': 'count'  # Count of trades\n",
    "    }).reset_index()\n",
    "    \n",
    "    grouped.rename(columns={'timestamp': 'trade_count'}, inplace=True)\n",
    "    \n",
    "    return grouped\n",
    "\n",
    "def prepare_visualization_data(grouped_df, current_time):\n",
    "    \"\"\"Prepare data for stacked bar chart visualization\"\"\"\n",
    "    if grouped_df.empty:\n",
    "        return None\n",
    "    \n",
    "    # Filter to recent time window\n",
    "    time_threshold = current_time - timedelta(seconds=TIME_WINDOW)\n",
    "    recent_data = grouped_df[grouped_df['time_bin'] >= time_threshold]\n",
    "    \n",
    "    if recent_data.empty:\n",
    "        return None\n",
    "    \n",
    "    # Pivot to get assets as columns\n",
    "    pivot_data = recent_data.pivot_table(\n",
    "        index='time_bin',\n",
    "        columns='asset_name',\n",
    "        values='price',\n",
    "        aggfunc='mean'\n",
    "    ).fillna(method='ffill').fillna(0)\n",
    "    \n",
    "    return pivot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Visualization Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LivePolymarketVisualizer:\n",
    "    \"\"\"Create and update live visualization of Polymarket trades\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_monitor):\n",
    "        self.csv_monitor = csv_monitor\n",
    "        self.all_data = pd.DataFrame()\n",
    "        \n",
    "        # Initialize plot\n",
    "        plt.style.use('seaborn-v0_8-darkgrid')\n",
    "        self.fig, self.ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        # Colors for assets\n",
    "        self.colors = ['#1f77b4', '#ff7f0e']  # Blue and orange\n",
    "        \n",
    "        # Initialize empty bars and line\n",
    "        self.bars = None\n",
    "        self.line = None\n",
    "        \n",
    "        # Configure axes\n",
    "        self.ax.set_ylim(0, 1)\n",
    "        self.ax.set_ylabel('Probability', fontsize=12)\n",
    "        self.ax.set_xlabel('DateTime', fontsize=12)\n",
    "        self.ax.set_title('Live Polymarket Trading Data - Asset Probabilities', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add grid\n",
    "        self.ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Create legend\n",
    "        self.ax.legend(['Asset A', 'Asset B', 'Combined'], loc='upper right')\n",
    "        \n",
    "        # Add value annotations\n",
    "        self.value_text = self.ax.text(0.02, 0.95, '', transform=self.ax.transAxes,\n",
    "                                      bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                                      verticalalignment='top')\n",
    "        \n",
    "    def update_data(self):\n",
    "        \"\"\"Fetch and process new data\"\"\"\n",
    "        # Get new data from CSV\n",
    "        new_data = self.csv_monitor.get_new_data()\n",
    "        \n",
    "        if new_data is not None and not new_data.empty:\n",
    "            # Append to all data\n",
    "            if self.all_data.empty:\n",
    "                self.all_data = new_data\n",
    "            else:\n",
    "                self.all_data = pd.concat([self.all_data, new_data], ignore_index=True)\n",
    "            \n",
    "            # Keep only recent data to manage memory\n",
    "            if len(self.all_data) > 10000:\n",
    "                self.all_data = self.all_data.tail(5000)\n",
    "    \n",
    "    def animate(self, frame):\n",
    "        \"\"\"Animation function for matplotlib\"\"\"\n",
    "        # Update data\n",
    "        self.update_data()\n",
    "        \n",
    "        if self.all_data.empty:\n",
    "            return\n",
    "        \n",
    "        # Process data\n",
    "        processed = process_trade_data(self.all_data)\n",
    "        if processed.empty:\n",
    "            return\n",
    "        \n",
    "        # Prepare visualization data\n",
    "        current_time = pd.Timestamp.now()\n",
    "        viz_data = prepare_visualization_data(processed, current_time)\n",
    "        \n",
    "        if viz_data is None or viz_data.empty:\n",
    "            return\n",
    "        \n",
    "        # Clear previous plot\n",
    "        self.ax.clear()\n",
    "        \n",
    "        # Create stacked bar chart\n",
    "        time_indices = viz_data.index\n",
    "        \n",
    "        # Prepare data for stacking\n",
    "        bottom = np.zeros(len(time_indices))\n",
    "        \n",
    "        # Plot bars for each asset\n",
    "        for i, asset in enumerate(['Asset A', 'Asset B']):\n",
    "            if asset in viz_data.columns:\n",
    "                values = viz_data[asset].values\n",
    "                self.ax.bar(time_indices, values, bottom=bottom, \n",
    "                           label=asset, color=self.colors[i], alpha=0.7, width=0.8)\n",
    "                bottom += values\n",
    "        \n",
    "        # Plot combined line (sum of probabilities)\n",
    "        if 'Asset A' in viz_data.columns and 'Asset B' in viz_data.columns:\n",
    "            combined = viz_data['Asset A'] + viz_data['Asset B']\n",
    "            self.ax.plot(time_indices, combined, 'k-', linewidth=2, \n",
    "                        marker='o', markersize=4, label='Combined')\n",
    "        \n",
    "        # Update labels and formatting\n",
    "        self.ax.set_ylim(0, 1.2)\n",
    "        self.ax.set_ylabel('Probability', fontsize=12)\n",
    "        self.ax.set_xlabel('DateTime', fontsize=12)\n",
    "        self.ax.set_title('Live Polymarket Trading Data - Asset Probabilities', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Rotate x-axis labels\n",
    "        plt.setp(self.ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "        \n",
    "        # Add legend\n",
    "        self.ax.legend(loc='upper right')\n",
    "        \n",
    "        # Add grid\n",
    "        self.ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Update value display\n",
    "        if not viz_data.empty:\n",
    "            latest_time = viz_data.index[-1]\n",
    "            value_text = f\"Latest Values ({latest_time.strftime('%H:%M:%S')})\\n\"\n",
    "            \n",
    "            if 'Asset A' in viz_data.columns:\n",
    "                value_text += f\"Asset A: {viz_data['Asset A'].iloc[-1]:.3f}\\n\"\n",
    "            if 'Asset B' in viz_data.columns:\n",
    "                value_text += f\"Asset B: {viz_data['Asset B'].iloc[-1]:.3f}\\n\"\n",
    "            \n",
    "            trade_count = len(self.all_data)\n",
    "            value_text += f\"\\nTotal Trades: {trade_count}\"\n",
    "            \n",
    "            self.value_text = self.ax.text(0.02, 0.95, value_text, \n",
    "                                         transform=self.ax.transAxes,\n",
    "                                         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                                         verticalalignment='top')\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the live animation\"\"\"\n",
    "        # Load initial data\n",
    "        self.all_data = self.csv_monitor.get_all_data()\n",
    "        \n",
    "        # Create animation\n",
    "        self.anim = FuncAnimation(self.fig, self.animate, interval=UPDATE_INTERVAL, \n",
    "                                 blit=False, cache_frame_data=False)\n",
    "        \n",
    "        return self.anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Live Streaming Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CSV monitor\n",
    "csv_monitor = CSVFileMonitor(CSV_FILE_PATH)\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(CSV_FILE_PATH):\n",
    "    print(f\"Warning: CSV file not found at {CSV_FILE_PATH}\")\n",
    "    print(\"Please ensure the file path is correct and the data service is running.\")\n",
    "else:\n",
    "    print(f\"Monitoring file: {CSV_FILE_PATH}\")\n",
    "    print(f\"File size: {os.path.getsize(CSV_FILE_PATH)} bytes\")\n",
    "    \n",
    "    # Create visualizer\n",
    "    visualizer = LivePolymarketVisualizer(csv_monitor)\n",
    "    \n",
    "    # Start live visualization\n",
    "    print(\"Starting live visualization...\")\n",
    "    print(\"The chart will update automatically as new data is written to the CSV file.\")\n",
    "    \n",
    "    animation = visualizer.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Simple Dashboard with Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_dashboard(duration_seconds=60):\n",
    "    \"\"\"Run a simple text-based dashboard\"\"\"\n",
    "    monitor = CSVFileMonitor(CSV_FILE_PATH)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Starting live dashboard...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    while (time.time() - start_time) < duration_seconds:\n",
    "        # Get all data\n",
    "        all_data = monitor.get_all_data()\n",
    "        \n",
    "        if not all_data.empty:\n",
    "            # Process data\n",
    "            processed = process_trade_data(all_data)\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            print(f\"LIVE POLYMARKET DATA DASHBOARD - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            # Latest values\n",
    "            if not processed.empty:\n",
    "                latest_time = processed['time_bin'].max()\n",
    "                latest_data = processed[processed['time_bin'] == latest_time]\n",
    "                \n",
    "                print(\"\\nLatest Prices:\")\n",
    "                for _, row in latest_data.iterrows():\n",
    "                    print(f\"  {row['asset_name']}: {row['price']:.4f} (Size: {row['size']:.2f})\")\n",
    "            \n",
    "            # Statistics\n",
    "            print(f\"\\nStatistics:\")\n",
    "            print(f\"  Total trades: {len(all_data)}\")\n",
    "            print(f\"  Time range: {all_data['datetime'].min()} to {all_data['datetime'].max()}\")\n",
    "            \n",
    "            # Price ranges by asset\n",
    "            print(\"\\nPrice Ranges:\")\n",
    "            for asset_id, asset_name in ASSET_NAMES.items():\n",
    "                asset_data = all_data[all_data['asset_id'] == asset_id]\n",
    "                if not asset_data.empty:\n",
    "                    print(f\"  {asset_name}:\")\n",
    "                    print(f\"    Min: {asset_data['price'].min():.4f}\")\n",
    "                    print(f\"    Max: {asset_data['price'].max():.4f}\")\n",
    "                    print(f\"    Mean: {asset_data['price'].mean():.4f}\")\n",
    "                    print(f\"    Std: {asset_data['price'].std():.4f}\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(f\"Monitoring for {duration_seconds - (time.time() - start_time):.0f} more seconds...\")\n",
    "        \n",
    "        await asyncio.sleep(2)\n",
    "    \n",
    "    print(\"\\nDashboard monitoring complete.\")\n",
    "\n",
    "# Run the dashboard for 60 seconds\n",
    "# await run_dashboard(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save processed data for analysis\n",
    "def save_processed_data(csv_monitor, output_path='processed_polymarket_data.csv'):\n",
    "    \"\"\"Load, process, and save the data\"\"\"\n",
    "    all_data = csv_monitor.get_all_data()\n",
    "    \n",
    "    if not all_data.empty:\n",
    "        processed = process_trade_data(all_data)\n",
    "        processed.to_csv(output_path, index=False)\n",
    "        print(f\"Processed data saved to: {output_path}\")\n",
    "        print(f\"Total records: {len(processed)}\")\n",
    "        return processed\n",
    "    else:\n",
    "        print(\"No data to process.\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "# processed_data = save_processed_data(csv_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides:\n",
    "\n",
    "1. **Live CSV Monitoring**: Continuously monitors the polymarket_trades.csv file for new data\n",
    "2. **Real-time Visualization**: Displays a stacked bar chart with:\n",
    "   - Asset A and Asset B probabilities as stacked bars\n",
    "   - Combined probability as a line overlay\n",
    "   - Live updates as new trades come in\n",
    "3. **Dashboard Alternative**: Text-based dashboard showing statistics and latest values\n",
    "4. **Data Processing**: Aggregates trades by time bins and calculates average prices\n",
    "\n",
    "The visualization matches the wireframe with:\n",
    "- Y-axis from 0 to 1 (probability)\n",
    "- X-axis showing datetime\n",
    "- Stacked bars for both assets\n",
    "- Line showing combined values\n",
    "- Legend and value display"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}