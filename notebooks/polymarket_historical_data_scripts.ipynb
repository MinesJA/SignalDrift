{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fe728c4-c588-4cf4-874d-3257bedf4afe",
   "metadata": {},
   "source": [
    "# Polymarket Historical Data Scripts\n",
    "\n",
    "Scripts to help download historical data from Polymarket from the Polymarket Analytics API\n",
    "\n",
    "> Note:\n",
    "> Polymarket Analytics doesn't have an official API but I was able to infer it by looking at the requests the sit was making.\n",
    "\n",
    "> TODO:\n",
    "> Should probably put everything into Claude and have it print out API docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e42bc02-6676-4ef2-8504-e157f1305e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'ticker', 'slug', 'title', 'description', 'resolutionSource',\n",
       "       'startDate', 'creationDate', 'endDate', 'image', 'icon', 'active',\n",
       "       'closed', 'archived', 'new', 'featured', 'restricted', 'liquidity',\n",
       "       'volume', 'openInterest', 'sortBy', 'category', 'published_at',\n",
       "       'createdAt', 'updatedAt', 'competitive', 'volume24hr', 'volume1wk',\n",
       "       'volume1mo', 'volume1yr', 'liquidityAmm', 'liquidityClob',\n",
       "       'commentCount', 'markets', 'series', 'tags', 'cyom', 'closedTime',\n",
       "       'showAllOutcomes', 'showMarketImages', 'enableNegRisk', 'seriesSlug',\n",
       "       'negRiskAugmented', 'pendingDeployment', 'deploying', 'subcategory',\n",
       "       'updatedBy', 'commentsEnabled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import traceback\n",
    "import requests  \n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import copy\n",
    "from src.config import config\n",
    "\n",
    "ACTIVITY_TRADES_URL = f\"{config.POLYMARKET_API_KEY}/api/activity-trades\"\n",
    "\n",
    "\n",
    "HEADERS = {\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Cookie\": f\"privy-session=t; privy-token={config.POLYMARKET_PRIVY_TOKEN}\",\n",
    "    \"Origin\": \"https://polymarketanalytics.com\",\n",
    "    \"Priority\": \"u=1, i\",\n",
    "    \"Sec-Ch-Ua\": '\"Not/A)Brand\";v=\"8\", \"Chromium\";v=\"126\"',\n",
    "    \"Sec-Ch-Ua-Mobile\": \"?0\",\n",
    "    \"Sec-Ch-Ua-Platform\": '\"Linux\"',\n",
    "    \"Sec-Fetch-Dest\": \"empty\",\n",
    "    \"Sec-Fetch-Mode\": \"cors\",\n",
    "    \"Sec-Fetch-Site\": \"same-origin\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetch_market_prices(market_id):\n",
    "    url = \"https://polymarketanalytics.com/api/markets-prices\"\n",
    "    data = {\"event_id\":market_id}\n",
    "\n",
    "    headers = copy.copy(HEADERS)\n",
    "    headers[\"Referer\"] = f\"https://polymarketanalytics.com/markets/{market_id}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        json_data = response.json()\n",
    "        trades = json_data.get('data', [])\n",
    "        \n",
    "        df = pd.DataFrame(trades)\n",
    "        # Convert trade_dttm to datetime for proper sorting and analysis\n",
    "        #df['trade_dttm'] = pd.to_datetime(df['trade_dttm'])\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error fetching {start_date} to {end_date}: {e}\")\n",
    "        return []\n",
    "    \n",
    "\n",
    "def fetch_positions(trader_id):\n",
    "    url = \"https://polymarketanalytics.com/api/traders-positions-history\"\n",
    "    data = {\"trader_id\": trader_id}\n",
    "\n",
    "    headers = copy.copy(HEADERS)\n",
    "    headers[\"Referer\"] = f\"https://polymarketanalytics.com/traders/{trader_id}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        json_data = response.json()\n",
    "        trades = json_data.get('data', [])\n",
    "        \n",
    "        df = pd.DataFrame(trades)\n",
    "        # Convert trade_dttm to datetime for proper sorting and analysis\n",
    "        df['trade_dt'] = pd.to_datetime(df['trade_dt'])\n",
    "        df['insert_time'] = pd.to_datetime(df['insert_time'])\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error fetching {start_date} to {end_date}: {e}\")\n",
    "        return []\n",
    "\n",
    "def fetch_user_trades_for_date_range(trader_id, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch trades for a specific date range.\n",
    "    \n",
    "    Args:\n",
    "        trader_id (str): Trader ID to fetch data for\n",
    "        start_date (str): Start date in YYYY-MM-DD format\n",
    "        end_date (str): End date in YYYY-MM-DD format\n",
    "        headers (dict): Request headers\n",
    "    \n",
    "    Returns:\n",
    "        list: List of trade records\n",
    "    \"\"\"\n",
    "    url = \"https://polymarketanalytics.com/api/activity-trades\"\n",
    "    \n",
    "    data = {\n",
    "        \"trader_id\": trader_id,\n",
    "        \"sortBy\": \"trade_dttm\",\n",
    "        \"sortDesc\": True,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=HEADERS, json=data)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        json_data = response.json()\n",
    "        trades = json_data.get('data', [])\n",
    "        \n",
    "        print(f\"  {start_date} to {end_date}: {len(trades)} trades\")\n",
    "        df = pd.DataFrame(trades)\n",
    "        # Convert trade_dttm to datetime for proper sorting and analysis\n",
    "        df['trade_dttm'] = pd.to_datetime(df['trade_dttm'])\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error fetching {start_date} to {end_date}: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def fetch_market_trades_for_date_range(event_id, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch trades for a specific date range.\n",
    "    \n",
    "    Args:\n",
    "        event_id (str): Event id\n",
    "        start_date (str): Start date in YYYY-MM-DD format\n",
    "        end_date (str): End date in YYYY-MM-DD format\n",
    "        headers (dict): Request headers\n",
    "    \n",
    "    Returns:\n",
    "        list: List of trade records\n",
    "    \"\"\"\n",
    "    url = \"https://polymarketanalytics.com/api/activity-trades\"\n",
    "    \n",
    "    data = {\n",
    "        \"event_id\": event_id,\n",
    "        \"sortBy\": \"trade_dttm\",\n",
    "        \"sortDesc\": True,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=HEADERS, json=data)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        json_data = response.json()\n",
    "        trades = json_data.get('data', [])\n",
    "        \n",
    "        print(f\"  {start_date} to {end_date}: {len(trades)} trades\")\n",
    "        df = pd.DataFrame(trades)\n",
    "        # Convert trade_dttm to datetime for proper sorting and analysis\n",
    "        df['trade_dttm'] = pd.to_datetime(df['trade_dttm'])\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error fetching {start_date} to {end_date}: {e}\")\n",
    "        return []\n",
    "\n",
    "#d = fetch_market_trades_for_date_range(\"16403\", \"2025-01-10 04:01:27\", \"2025-01-10 05:01:28\")\n",
    "# Example of fetching specific date range:\n",
    "\n",
    "def fetch_price_history(clob_id, start_date=None, end_date=None, interval=None, fidelity=1):\n",
    "    \"\"\"\n",
    "    Get price history for a specific token.\n",
    "    \n",
    "    Args:\n",
    "        clob_id (str): CLOB token ID\n",
    "        start_ts (int): Start timestamp (Unix, UTC)\n",
    "        end_ts (int): End timestamp (Unix, UTC)\n",
    "        interval (str): Time interval (\"1m\", \"1w\", \"1d\", \"6h\", \"1h\", \"max\")\n",
    "        fidelity (int): Resolution in minutes (1 = 1 minute intervals)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Price history data\n",
    "    \"\"\"\n",
    "    \n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'User-Agent': 'Mozilla/5.0 (compatible; PolymarketAPI/1.0)'\n",
    "    }\n",
    "    \n",
    "    url = \"https://clob.polymarket.com/prices-history\"\n",
    "    \n",
    "    params = {\n",
    "        'market': clob_id,\n",
    "        'fidelity': fidelity\n",
    "    }\n",
    "    \n",
    "    # Use either timestamp range OR interval (mutually exclusive)\n",
    "    if start_date and end_date:\n",
    "        params['startTs'] = int(datetime.strptime(start_date, '%Y-%m-%dT%H:%M:%SZ').replace(tzinfo=timezone.utc).timestamp())\n",
    "        params['endTs'] = int(datetime.strptime(end_date, '%Y-%m-%dT%H:%M:%SZ').replace(tzinfo=timezone.utc).timestamp())\n",
    "        \n",
    "        #params['startTs'] = int(datetime.strptime(start_date, \"%Y-%m-%d\").timestamp())\n",
    "        #params['endTs'] = int(datetime.strptime(end_date, \"%Y-%m-%d\").timestamp())\n",
    "    elif interval:\n",
    "        params['interval'] = interval\n",
    "    else:\n",
    "        params['interval'] = 'all'\n",
    "    \n",
    "    try:\n",
    "        print(f\"Fetching price history for token {clob_id}...\")\n",
    "        print(f\"Parameters: {params}\")\n",
    "        \n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        if 'history' in data and data['history']:\n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(data['history'])\n",
    "            \n",
    "            # Convert timestamp to datetime\n",
    "            df['datetime'] = pd.to_datetime(df['t'], unit='s')\n",
    "            df['price'] = df['p']\n",
    "            \n",
    "            # Sort by time\n",
    "            df = df.sort_values('datetime').reset_index(drop=True)\n",
    "            \n",
    "            print(f\"Retrieved {len(df)} price points\")\n",
    "            print(f\"Date range: {df['datetime'].min()} to {df['datetime'].max()}\")\n",
    "            \n",
    "            return df[['datetime', 'price', 't', 'p']]\n",
    "        \n",
    "        else:\n",
    "            print(\"No price history data found\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching price history: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def fetch_events():\n",
    "    url = f\"https://gamma-api.polymarket.com/events?closed=true&include_chat=false\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        #return response.json()\n",
    "\n",
    "        return pd.DataFrame(response.json())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "def fetch_event(slug):\n",
    "    url = f\"https://gamma-api.polymarket.com/events/slug/{slug}?include_chat=false\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "\n",
    "fetch_events().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a60131c7-d7fe-4235-9774-fdeaa8cc4db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching price history for token 3300671900186020957198642358934489067292273503243368402087506893833088463182...\n",
      "Parameters: {'market': '3300671900186020957198642358934489067292273503243368402087506893833088463182', 'fidelity': 1, 'interval': 'all'}\n",
      "Retrieved 233 price points\n",
      "Date range: 2025-05-30 08:20:07 to 2025-05-31 23:00:07\n",
      "Fetching price history for token 14315604171938534486956636006407315271580153618606169226574246432618720078259...\n",
      "Parameters: {'market': '14315604171938534486956636006407315271580153618606169226574246432618720078259', 'fidelity': 1, 'interval': 'all'}\n",
      "Retrieved 233 price points\n",
      "Date range: 2025-05-30 08:20:07 to 2025-05-31 23:00:07\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>price</th>\n",
       "      <th>t</th>\n",
       "      <th>p</th>\n",
       "      <th>clobTokenId</th>\n",
       "      <th>outcome</th>\n",
       "      <th>conditionId</th>\n",
       "      <th>gameStartTime</th>\n",
       "      <th>marketId</th>\n",
       "      <th>marketStartDate</th>\n",
       "      <th>marketEndDate</th>\n",
       "      <th>startDate</th>\n",
       "      <th>endDate</th>\n",
       "      <th>slug</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-30 08:20:07</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1748593207</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>3300671900186020957198642358934489067292273503...</td>\n",
       "      <td>Reds</td>\n",
       "      <td>0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...</td>\n",
       "      <td>2025-05-31 18:20:00+00</td>\n",
       "      <td>548355</td>\n",
       "      <td>2025-05-30T08:01:01.277266Z</td>\n",
       "      <td>2025-06-07T18:20:00Z</td>\n",
       "      <td>2025-05-30T08:02:35.864221Z</td>\n",
       "      <td>2025-05-31T18:20:00Z</td>\n",
       "      <td>mlb-cin-chc-2025-05-31</td>\n",
       "      <td>Reds vs. Cubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-30 08:30:07</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1748593807</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>3300671900186020957198642358934489067292273503...</td>\n",
       "      <td>Reds</td>\n",
       "      <td>0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...</td>\n",
       "      <td>2025-05-31 18:20:00+00</td>\n",
       "      <td>548355</td>\n",
       "      <td>2025-05-30T08:01:01.277266Z</td>\n",
       "      <td>2025-06-07T18:20:00Z</td>\n",
       "      <td>2025-05-30T08:02:35.864221Z</td>\n",
       "      <td>2025-05-31T18:20:00Z</td>\n",
       "      <td>mlb-cin-chc-2025-05-31</td>\n",
       "      <td>Reds vs. Cubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-30 08:40:07</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1748594407</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>3300671900186020957198642358934489067292273503...</td>\n",
       "      <td>Reds</td>\n",
       "      <td>0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...</td>\n",
       "      <td>2025-05-31 18:20:00+00</td>\n",
       "      <td>548355</td>\n",
       "      <td>2025-05-30T08:01:01.277266Z</td>\n",
       "      <td>2025-06-07T18:20:00Z</td>\n",
       "      <td>2025-05-30T08:02:35.864221Z</td>\n",
       "      <td>2025-05-31T18:20:00Z</td>\n",
       "      <td>mlb-cin-chc-2025-05-31</td>\n",
       "      <td>Reds vs. Cubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-30 08:50:07</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1748595007</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>3300671900186020957198642358934489067292273503...</td>\n",
       "      <td>Reds</td>\n",
       "      <td>0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...</td>\n",
       "      <td>2025-05-31 18:20:00+00</td>\n",
       "      <td>548355</td>\n",
       "      <td>2025-05-30T08:01:01.277266Z</td>\n",
       "      <td>2025-06-07T18:20:00Z</td>\n",
       "      <td>2025-05-30T08:02:35.864221Z</td>\n",
       "      <td>2025-05-31T18:20:00Z</td>\n",
       "      <td>mlb-cin-chc-2025-05-31</td>\n",
       "      <td>Reds vs. Cubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-30 09:00:08</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1748595608</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>3300671900186020957198642358934489067292273503...</td>\n",
       "      <td>Reds</td>\n",
       "      <td>0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...</td>\n",
       "      <td>2025-05-31 18:20:00+00</td>\n",
       "      <td>548355</td>\n",
       "      <td>2025-05-30T08:01:01.277266Z</td>\n",
       "      <td>2025-06-07T18:20:00Z</td>\n",
       "      <td>2025-05-30T08:02:35.864221Z</td>\n",
       "      <td>2025-05-31T18:20:00Z</td>\n",
       "      <td>mlb-cin-chc-2025-05-31</td>\n",
       "      <td>Reds vs. Cubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2025-05-31 22:20:07</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1748730007</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1431560417193853448695663600640731527158015361...</td>\n",
       "      <td>Cubs</td>\n",
       "      <td>0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...</td>\n",
       "      <td>2025-05-31 18:20:00+00</td>\n",
       "      <td>548355</td>\n",
       "      <td>2025-05-30T08:01:01.277266Z</td>\n",
       "      <td>2025-06-07T18:20:00Z</td>\n",
       "      <td>2025-05-30T08:02:35.864221Z</td>\n",
       "      <td>2025-05-31T18:20:00Z</td>\n",
       "      <td>mlb-cin-chc-2025-05-31</td>\n",
       "      <td>Reds vs. Cubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2025-05-31 22:30:07</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1748730607</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1431560417193853448695663600640731527158015361...</td>\n",
       "      <td>Cubs</td>\n",
       "      <td>0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...</td>\n",
       "      <td>2025-05-31 18:20:00+00</td>\n",
       "      <td>548355</td>\n",
       "      <td>2025-05-30T08:01:01.277266Z</td>\n",
       "      <td>2025-06-07T18:20:00Z</td>\n",
       "      <td>2025-05-30T08:02:35.864221Z</td>\n",
       "      <td>2025-05-31T18:20:00Z</td>\n",
       "      <td>mlb-cin-chc-2025-05-31</td>\n",
       "      <td>Reds vs. Cubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2025-05-31 22:40:07</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1748731207</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1431560417193853448695663600640731527158015361...</td>\n",
       "      <td>Cubs</td>\n",
       "      <td>0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...</td>\n",
       "      <td>2025-05-31 18:20:00+00</td>\n",
       "      <td>548355</td>\n",
       "      <td>2025-05-30T08:01:01.277266Z</td>\n",
       "      <td>2025-06-07T18:20:00Z</td>\n",
       "      <td>2025-05-30T08:02:35.864221Z</td>\n",
       "      <td>2025-05-31T18:20:00Z</td>\n",
       "      <td>mlb-cin-chc-2025-05-31</td>\n",
       "      <td>Reds vs. Cubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2025-05-31 22:50:07</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1748731807</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1431560417193853448695663600640731527158015361...</td>\n",
       "      <td>Cubs</td>\n",
       "      <td>0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...</td>\n",
       "      <td>2025-05-31 18:20:00+00</td>\n",
       "      <td>548355</td>\n",
       "      <td>2025-05-30T08:01:01.277266Z</td>\n",
       "      <td>2025-06-07T18:20:00Z</td>\n",
       "      <td>2025-05-30T08:02:35.864221Z</td>\n",
       "      <td>2025-05-31T18:20:00Z</td>\n",
       "      <td>mlb-cin-chc-2025-05-31</td>\n",
       "      <td>Reds vs. Cubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2025-05-31 23:00:07</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1748732407</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>1431560417193853448695663600640731527158015361...</td>\n",
       "      <td>Cubs</td>\n",
       "      <td>0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...</td>\n",
       "      <td>2025-05-31 18:20:00+00</td>\n",
       "      <td>548355</td>\n",
       "      <td>2025-05-30T08:01:01.277266Z</td>\n",
       "      <td>2025-06-07T18:20:00Z</td>\n",
       "      <td>2025-05-30T08:02:35.864221Z</td>\n",
       "      <td>2025-05-31T18:20:00Z</td>\n",
       "      <td>mlb-cin-chc-2025-05-31</td>\n",
       "      <td>Reds vs. Cubs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>466 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime   price           t       p  \\\n",
       "0   2025-05-30 08:20:07  0.5000  1748593207  0.5000   \n",
       "1   2025-05-30 08:30:07  0.5000  1748593807  0.5000   \n",
       "2   2025-05-30 08:40:07  0.5000  1748594407  0.5000   \n",
       "3   2025-05-30 08:50:07  0.5000  1748595007  0.5000   \n",
       "4   2025-05-30 09:00:08  0.5000  1748595608  0.5000   \n",
       "..                  ...     ...         ...     ...   \n",
       "228 2025-05-31 22:20:07  0.9995  1748730007  0.9995   \n",
       "229 2025-05-31 22:30:07  0.9995  1748730607  0.9995   \n",
       "230 2025-05-31 22:40:07  0.9995  1748731207  0.9995   \n",
       "231 2025-05-31 22:50:07  0.9995  1748731807  0.9995   \n",
       "232 2025-05-31 23:00:07  0.9995  1748732407  0.9995   \n",
       "\n",
       "                                           clobTokenId outcome  \\\n",
       "0    3300671900186020957198642358934489067292273503...    Reds   \n",
       "1    3300671900186020957198642358934489067292273503...    Reds   \n",
       "2    3300671900186020957198642358934489067292273503...    Reds   \n",
       "3    3300671900186020957198642358934489067292273503...    Reds   \n",
       "4    3300671900186020957198642358934489067292273503...    Reds   \n",
       "..                                                 ...     ...   \n",
       "228  1431560417193853448695663600640731527158015361...    Cubs   \n",
       "229  1431560417193853448695663600640731527158015361...    Cubs   \n",
       "230  1431560417193853448695663600640731527158015361...    Cubs   \n",
       "231  1431560417193853448695663600640731527158015361...    Cubs   \n",
       "232  1431560417193853448695663600640731527158015361...    Cubs   \n",
       "\n",
       "                                           conditionId  \\\n",
       "0    0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...   \n",
       "1    0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...   \n",
       "2    0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...   \n",
       "3    0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...   \n",
       "4    0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...   \n",
       "..                                                 ...   \n",
       "228  0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...   \n",
       "229  0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...   \n",
       "230  0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...   \n",
       "231  0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...   \n",
       "232  0x6d6f388a856a387f19a5c9db3dda811f8bc3e46f99e0...   \n",
       "\n",
       "              gameStartTime marketId              marketStartDate  \\\n",
       "0    2025-05-31 18:20:00+00   548355  2025-05-30T08:01:01.277266Z   \n",
       "1    2025-05-31 18:20:00+00   548355  2025-05-30T08:01:01.277266Z   \n",
       "2    2025-05-31 18:20:00+00   548355  2025-05-30T08:01:01.277266Z   \n",
       "3    2025-05-31 18:20:00+00   548355  2025-05-30T08:01:01.277266Z   \n",
       "4    2025-05-31 18:20:00+00   548355  2025-05-30T08:01:01.277266Z   \n",
       "..                      ...      ...                          ...   \n",
       "228  2025-05-31 18:20:00+00   548355  2025-05-30T08:01:01.277266Z   \n",
       "229  2025-05-31 18:20:00+00   548355  2025-05-30T08:01:01.277266Z   \n",
       "230  2025-05-31 18:20:00+00   548355  2025-05-30T08:01:01.277266Z   \n",
       "231  2025-05-31 18:20:00+00   548355  2025-05-30T08:01:01.277266Z   \n",
       "232  2025-05-31 18:20:00+00   548355  2025-05-30T08:01:01.277266Z   \n",
       "\n",
       "            marketEndDate                    startDate               endDate  \\\n",
       "0    2025-06-07T18:20:00Z  2025-05-30T08:02:35.864221Z  2025-05-31T18:20:00Z   \n",
       "1    2025-06-07T18:20:00Z  2025-05-30T08:02:35.864221Z  2025-05-31T18:20:00Z   \n",
       "2    2025-06-07T18:20:00Z  2025-05-30T08:02:35.864221Z  2025-05-31T18:20:00Z   \n",
       "3    2025-06-07T18:20:00Z  2025-05-30T08:02:35.864221Z  2025-05-31T18:20:00Z   \n",
       "4    2025-06-07T18:20:00Z  2025-05-30T08:02:35.864221Z  2025-05-31T18:20:00Z   \n",
       "..                    ...                          ...                   ...   \n",
       "228  2025-06-07T18:20:00Z  2025-05-30T08:02:35.864221Z  2025-05-31T18:20:00Z   \n",
       "229  2025-06-07T18:20:00Z  2025-05-30T08:02:35.864221Z  2025-05-31T18:20:00Z   \n",
       "230  2025-06-07T18:20:00Z  2025-05-30T08:02:35.864221Z  2025-05-31T18:20:00Z   \n",
       "231  2025-06-07T18:20:00Z  2025-05-30T08:02:35.864221Z  2025-05-31T18:20:00Z   \n",
       "232  2025-06-07T18:20:00Z  2025-05-30T08:02:35.864221Z  2025-05-31T18:20:00Z   \n",
       "\n",
       "                       slug          title  \n",
       "0    mlb-cin-chc-2025-05-31  Reds vs. Cubs  \n",
       "1    mlb-cin-chc-2025-05-31  Reds vs. Cubs  \n",
       "2    mlb-cin-chc-2025-05-31  Reds vs. Cubs  \n",
       "3    mlb-cin-chc-2025-05-31  Reds vs. Cubs  \n",
       "4    mlb-cin-chc-2025-05-31  Reds vs. Cubs  \n",
       "..                      ...            ...  \n",
       "228  mlb-cin-chc-2025-05-31  Reds vs. Cubs  \n",
       "229  mlb-cin-chc-2025-05-31  Reds vs. Cubs  \n",
       "230  mlb-cin-chc-2025-05-31  Reds vs. Cubs  \n",
       "231  mlb-cin-chc-2025-05-31  Reds vs. Cubs  \n",
       "232  mlb-cin-chc-2025-05-31  Reds vs. Cubs  \n",
       "\n",
       "[466 rows x 15 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "event = fetch_event(\"mlb-cin-chc-2025-05-31\")\n",
    "\n",
    "flattened = [\n",
    "    {'clobTokenId': token_id, \n",
    "     'outcome': outcome,\n",
    "     'conditionId': m['conditionId'], \n",
    "     'gameStartTime': m['gameStartTime'], \n",
    "     'marketId': m['id'],\n",
    "     'marketStartDate': m['startDate'], \n",
    "     'marketEndDate': m['endDate'], \n",
    "     'startDate': event['startDate'],\n",
    "     'endDate': event['endDate'],\n",
    "     'gameStartTime': m['gameStartTime'], \n",
    "     'slug': event['slug'], \n",
    "     'title': event['title']\n",
    "    }\n",
    "    for m in event['markets'] \n",
    "    if 'clobTokenIds' in m\n",
    "    for token_id, outcome in zip(json.loads(m['clobTokenIds']), json.loads(m['outcomes']))\n",
    "]\n",
    "\n",
    "a = [fetch_price_history(x['clobTokenId']).assign(**x) for x in flattened]\n",
    "combined = pd.concat(a, join='inner')\n",
    "\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f934a296-ea25-42f0-901b-62d0220ab89d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m data_dir = \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m os.makedirs(data_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m csv_filename = os.path.join(\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpoly_market_prices_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43md\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mevent_id\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Save to CSV file\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#csv_filename = f\"polymarket_trades_{data['trader_id'][:8]}.csv\"\u001b[39;00m\n\u001b[32m      9\u001b[39m d.to_csv(csv_filename, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    " # Create data directory if it doesn't exist\n",
    "data_dir = \"data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "csv_filename = os.path.join('data', f\"poly_market_prices_{d['event_id'][0]}_{timestamp}.csv\")\n",
    "\n",
    "# Save to CSV file\n",
    "#csv_filename = f\"polymarket_trades_{data['trader_id'][:8]}.csv\"\n",
    "d.to_csv(csv_filename, index=False)\n",
    "print(f\"\\nData saved to: {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd9ff001-c816-4cd3-8f7d-16236353ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "\n",
    "def generate_date_ranges(start_date, end_date, chunk_hours=2):\n",
    "    \"\"\"\n",
    "    Generate date ranges for iteration in hour chunks.\n",
    "    \n",
    "    Args:\n",
    "        start_date (str): Overall start date (YYYY-MM-DD)\n",
    "        end_date (str): Overall end date (YYYY-MM-DD)\n",
    "        chunk_hours (int): Number of hours per chunk\n",
    "    \n",
    "    Returns:\n",
    "        list: List of (start_datetime, end_datetime) tuples in ISO format\n",
    "    \"\"\"\n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\").replace(hour=23, minute=59, second=59)\n",
    "    \n",
    "    date_ranges = []\n",
    "    current_start = start\n",
    "    \n",
    "    while current_start < end:\n",
    "        current_end = min(current_start + timedelta(hours=chunk_hours), end)\n",
    "        date_ranges.append((\n",
    "            current_start.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "            current_end.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "        ))\n",
    "        current_start = current_end + timedelta(seconds=1)  # Move to next second to avoid overlap\n",
    "    \n",
    "    return date_ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8bcd2c5-a712-4600-8423-4a7d94ef7bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for trader 0xb49f468c... from 2025-05-29 to 2025-05-30\n",
      "Using 3-hour chunks with 0.3s delay between requests\n",
      "Will make 16 API requests\n",
      "Request 1/16: 2025-05-29T00:00:00 to 2025-05-29T03:00:00 "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fetch_trades_for_date_range() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 97\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDate range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mtrade_dttm\u001b[39m\u001b[33m'\u001b[39m].min()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mtrade_dttm\u001b[39m\u001b[33m'\u001b[39m].max()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[43mfetch_all_trader_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrader_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m0xb49f468c15c49783f2664c7198a4949ade1b12e6\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2025-05-29\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2025-05-30\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_hours\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Faster requests for smaller chunks\u001b[39;49;00m\n\u001b[32m    103\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mfetch_all_trader_data\u001b[39m\u001b[34m(trader_id, start_date, end_date, chunk_hours, delay)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (range_start, range_end) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(date_ranges, \u001b[32m1\u001b[39m):\n\u001b[32m     56\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRequest \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(date_ranges)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrange_start\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrange_end\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     trades = \u001b[43mfetch_trades_for_date_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrader_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrange_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrange_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     all_trades.extend(trades)\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# Add delay between requests to be respectful\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: fetch_trades_for_date_range() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "def fetch_all_trader_data(trader_id, start_date, end_date, chunk_hours=2, delay=0.5):\n",
    "    \"\"\"\n",
    "    Fetch all trading data for a trader across a date range, using chunked requests.\n",
    "    \n",
    "    For very active traders, try 1-hour chunks\n",
    "    df = fetch_all_trader_data(\n",
    "        trader_id=trader_id,\n",
    "        start_date=\"2025-05-30\",\n",
    "        end_date=\"2025-05-30\",\n",
    "        chunk_hours=1,\n",
    "        delay=0.3  # Faster requests for smaller chunks\n",
    "    )\n",
    "     \n",
    "    Args:\n",
    "        trader_id (str): Trader ID to fetch data for\n",
    "        start_date (str): Start date (YYYY-MM-DD)\n",
    "        end_date (str): End date (YYYY-MM-DD)\n",
    "        chunk_hours (int): Hours per API request (default: 2)\n",
    "        delay (float): Delay between requests in seconds\n",
    "\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame with all trades\n",
    "    \"\"\"\n",
    "    \n",
    "    # Request headers (update with your current session)\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Cookie\": f\"privy-session=t; privy-token={config.POLYMARKET_PRIVY_TOKEN}\",\n",
    "        \"Origin\": \"https://polymarketanalytics.com\",\n",
    "        \"Priority\": \"u=1, i\",\n",
    "        \"Referer\": \"https://polymarketanalytics.com/traders/0xd218e474776403a330142299f7796e8ba32eb5c9\",\n",
    "        \"Sec-Ch-Ua\": '\"Not/A)Brand\";v=\"8\", \"Chromium\";v=\"126\"',\n",
    "        \"Sec-Ch-Ua-Mobile\": \"?0\",\n",
    "        \"Sec-Ch-Ua-Platform\": '\"Linux\"',\n",
    "        \"Sec-Fetch-Dest\": \"empty\",\n",
    "        \"Sec-Fetch-Mode\": \"cors\",\n",
    "        \"Sec-Fetch-Site\": \"same-origin\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    print(f\"Fetching data for trader {trader_id[:10]}... from {start_date} to {end_date}\")\n",
    "    print(f\"Using {chunk_hours}-hour chunks with {delay}s delay between requests\")\n",
    "    \n",
    "    # Generate date ranges\n",
    "    date_ranges = generate_date_ranges(start_date, end_date, chunk_hours)\n",
    "    print(f\"Will make {len(date_ranges)} API requests\")\n",
    "    \n",
    "    all_trades = []\n",
    "    \n",
    "    for i, (range_start, range_end) in enumerate(date_ranges, 1):\n",
    "        print(f\"Request {i}/{len(date_ranges)}: {range_start} to {range_end}\", end=\" \")\n",
    "        \n",
    "        trades = fetch_trades_for_date_range(trader_id, range_start, range_end, headers)\n",
    "        all_trades.extend(trades)\n",
    "        \n",
    "        # Add delay between requests to be respectful\n",
    "        if i < len(date_ranges):\n",
    "            time.sleep(delay)\n",
    "        \n",
    "        # Progress update every 50 requests\n",
    "        if i % 50 == 0:\n",
    "            print(f\"\\n  --> Progress: {i}/{len(date_ranges)} requests completed, {len(all_trades)} total trades so far\")\n",
    "    \n",
    "    print(f\"\\nTotal trades collected: {len(all_trades)}\")\n",
    "    \n",
    "    if not all_trades:\n",
    "        print(\"No trades found!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_trades)\n",
    "    df['trade_dttm'] = pd.to_datetime(df['trade_dttm'])\n",
    "    \n",
    "    # Remove any duplicates (in case of overlapping date ranges)\n",
    "    initial_count = len(df)\n",
    "    df = df.drop_duplicates(subset=['trade_dttm', 'trader_id', 'amount', 'price', 'market_title', 'outcome'])\n",
    "    final_count = len(df)\n",
    "    \n",
    "    if initial_count != final_count:\n",
    "        print(f\"Removed {initial_count - final_count} duplicate trades\")\n",
    "    \n",
    "    # Sort by trade datetime\n",
    "    df = df.sort_values('trade_dttm', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Final dataset: {len(df)} unique trades\")\n",
    "    print(f\"Date range: {df['trade_dttm'].min()} to {df['trade_dttm'].max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "fetch_all_trader_data(\n",
    "    trader_id=\"0xb49f468c15c49783f2664c7198a4949ade1b12e6\",\n",
    "    start_date=\"2025-05-29\",\n",
    "    end_date=\"2025-05-30\",\n",
    "    chunk_hours=3,\n",
    "    delay=0.3  # Faster requests for smaller chunks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1bdf55a-7f6c-4d5f-b363-2dd57abe9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def create_csv(dataframe):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "     # Create data directory if it doesn't exist\n",
    "    data_dir = \"data\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    csv_filename = os.path.join('data', f\"poly_user_activity_trades_{data['trader_id'][:8]}_{timestamp}.csv\")\n",
    "    \n",
    "    # Save to CSV file\n",
    "    #csv_filename = f\"polymarket_trades_{data['trader_id'][:8]}.csv\"\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"\\nData saved to: {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb5417a5-4484-4c22-a48a-eb2aa83f7bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Number of trades returned: 1000\n",
      "\n",
      "DataFrame shape: (1000, 13)\n",
      "\n",
      "Trade time range:\n",
      "Earliest trade: 2025-05-26 18:25:17\n",
      "Latest trade:   2025-05-30 17:50:15\n",
      "Time span:      3 days 23:24:58\n",
      "\n",
      "Data saved to: data/poly_user_activity_trades_0xb49f46_202505301116.csv\n",
      "Status Code: 200\n",
      "Number of trades returned: 1000\n",
      "\n",
      "DataFrame shape: (1000, 13)\n",
      "\n",
      "Trade time range:\n",
      "Earliest trade: 2025-05-30 13:34:41\n",
      "Latest trade:   2025-05-30 18:14:43\n",
      "Time span:      0 days 04:40:02\n",
      "\n",
      "Data saved to: data/poly_user_activity_trades_0xb49f46_202505301116.csv\n",
      "Status Code: 200\n",
      "Number of trades returned: 1000\n",
      "\n",
      "DataFrame shape: (1000, 13)\n",
      "\n",
      "Trade time range:\n",
      "Earliest trade: 2025-05-30 12:09:24\n",
      "Latest trade:   2025-05-30 18:13:59\n",
      "Time span:      0 days 06:04:35\n",
      "\n",
      "Data saved to: data/poly_user_activity_trades_0xb49f46_202505301116.csv\n"
     ]
    }
   ],
   "source": [
    "# Save data to CSVs for each trader\n",
    "\n",
    "trader_ids = [\"0xb49f468c15c49783f2664c7198a4949ade1b12e6\", \"0xd218e474776403a330142299f7796e8ba32eb5c9\", \"0xe3726a1b9c6ba2f06585d1c9e01d00afaedaeb38\"]\n",
    "\n",
    "df = fetch_activity_trades(id)\n",
    "\n",
    "for id in trader_ids:\n",
    "    df = fetch_activity_trades(id)\n",
    "    # Convert trade_dttm to datetime for proper sorting and analysis\n",
    "    df['trade_dttm'] = pd.to_datetime(df['trade_dttm'])\n",
    "    \n",
    "    # Find earliest and latest trade times\n",
    "    earliest_trade = df['trade_dttm'].min()\n",
    "    latest_trade = df['trade_dttm'].max()\n",
    "    \n",
    "    print(f\"\\nTrade time range:\")\n",
    "    print(f\"Earliest trade: {earliest_trade}\")\n",
    "    print(f\"Latest trade:   {latest_trade}\")\n",
    "    print(f\"Time span:      {latest_trade - earliest_trade}\")\n",
    "    create_csv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d9d82cf-90e9-4cae-a462-f8f8bfa5b7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poly_user_activity_trades_0xb49f46_202505301114.csv',\n",
       " 'poly_user_activity_trades_0xb49f46_202505301115.csv',\n",
       " 'poly_user_activity_trades_0xb49f46_202505301116.csv',\n",
       " 'poly_user_activity_trades_0xb49f46_202505301041.csv',\n",
       " 'poly_user_activity_trades_0xd218e4_202505301037.csv']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all files in data\n",
    "trader_ids = [\"0xb49f468c15c49783f2664c7198a4949ade1b12e6\", \"0xd218e474776403a330142299f7796e8ba32eb5c9\", \"0xe3726a1b9c6ba2f06585d1c9e01d00afaedaeb38\"]\n",
    "\n",
    "fetch_activity_trades(trader_ids[0])\n",
    "all_files = os.listdir('data')\n",
    "files = [f for f in all_files if f.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bd6b21-cf9a-487d-a545-5d9d0df5d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_historical_data(trader_id, start_date, end_date, chunk_hours=2):\n",
    "    \"\"\"\n",
    "    Fetch and save historical trading data for a trader.\n",
    "    \n",
    "    Args:\n",
    "        trader_id (str): Trader ID\n",
    "        start_date (str): Start date (YYYY-MM-DD)\n",
    "        end_date (str): End date (YYYY-MM-DD)\n",
    "        chunk_hours (int): Hours per request\n",
    "    \n",
    "    Returns:\n",
    "        str: Filename of saved CSV\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fetch the data\n",
    "    df = fetch_all_trader_data(trader_id, start_date, end_date, chunk_hours)\n",
    "    \n",
    "    if df.empty:\n",
    "        return None\n",
    "    \n",
    "    # Save to CSV\n",
    "    data_dir = \"data\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "    filename = f\"polymarket_trades_{trader_id[:8]}_{start_date}_{end_date}_{timestamp}.csv\"\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "    \n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"\\nData saved to: {filepath}\")\n",
    "    \n",
    "    return filename\n",
    "\n",
    "# Example usage:\n",
    "# \n",
    "# # Fetch 1 day of data in 2-hour chunks (12 requests)\n",
    "# trader_id = \"0xd218e474776403a330142299f7796e8ba32eb5c9\"\n",
    "# filename = save_historical_data(\n",
    "#     trader_id=trader_id,\n",
    "#     start_date=\"2025-05-29\", \n",
    "#     end_date=\"2025-05-30\",\n",
    "#     chunk_hours=2\n",
    "# )\n",
    "# \n",
    "# # For very active traders, try 1-hour chunks\n",
    "# df = fetch_all_trader_data(\n",
    "#     trader_id=trader_id,\n",
    "#     start_date=\"2025-05-30\",\n",
    "#     end_date=\"2025-05-30\",\n",
    "#     chunk_hours=1,\n",
    "#     delay=0.3  # Faster requests for smaller chunks\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821711ab-773e-4787-9bbb-c9937e782d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def analyze_market_maker_characteristics(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Analyze trading patterns to identify potential market makers.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with trade data\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Analysis results by trader\n",
    "    \"\"\"\n",
    "    \n",
    "    # Group by trader for analysis\n",
    "    trader_stats = df.groupby('trader_id').agg({\n",
    "        'amount': ['count', 'mean', 'std', 'sum'],\n",
    "        'value': ['mean', 'sum'],\n",
    "        'side': lambda x: list(x),\n",
    "        'market_title': 'nunique',\n",
    "        'outcome': lambda x: list(x),\n",
    "        'price': ['mean', 'std'],\n",
    "        'trade_dttm': ['min', 'max']\n",
    "    }).round(4)\n",
    "    \n",
    "    # Flatten column names\n",
    "    trader_stats.columns = ['_'.join(col).strip() for col in trader_stats.columns]\n",
    "    \n",
    "    # Calculate market maker indicators\n",
    "    mm_indicators = []\n",
    "    \n",
    "    for trader_id, row in trader_stats.iterrows():\n",
    "        trader_trades = df[df['trader_id'] == trader_id]\n",
    "        \n",
    "        # 1. LARGE ORDER SIZES\n",
    "        avg_trade_size = row['amount_mean']\n",
    "        trade_size_percentile = (trader_trades['amount'] >= trader_trades['amount'].quantile(0.8)).mean()\n",
    "        \n",
    "        # 2. BOTH SIDES OF TRADE\n",
    "        sides = trader_trades['side'].value_counts()\n",
    "        buy_ratio = sides.get('buy', 0) / len(trader_trades)\n",
    "        sell_ratio = sides.get('sell', 0) / len(trader_trades)\n",
    "        both_sides_score = 1 - abs(buy_ratio - sell_ratio)  # Closer to 1 = more balanced\n",
    "        \n",
    "        # 3. DIVERSIFICATION (across markets and outcomes)\n",
    "        unique_markets = row['market_title_nunique']\n",
    "        total_trades = row['amount_count']\n",
    "        market_diversification = unique_markets / total_trades if total_trades > 0 else 0\n",
    "        \n",
    "        # Outcome diversification within markets\n",
    "        outcome_balance_scores = []\n",
    "        for market in trader_trades['market_title'].unique():\n",
    "            market_trades = trader_trades[trader_trades['market_title'] == market]\n",
    "            if len(market_trades) > 1:\n",
    "                outcome_counts = market_trades['outcome'].value_counts()\n",
    "                # Calculate balance between Yes/No outcomes\n",
    "                yes_ratio = outcome_counts.get('Yes', 0) / len(market_trades)\n",
    "                no_ratio = outcome_counts.get('No', 0) / len(market_trades)\n",
    "                balance_score = 1 - abs(yes_ratio - no_ratio)\n",
    "                outcome_balance_scores.append(balance_score)\n",
    "        \n",
    "        avg_outcome_balance = np.mean(outcome_balance_scores) if outcome_balance_scores else 0\n",
    "        \n",
    "        # 4. TRADING FREQUENCY\n",
    "        date_range = (pd.to_datetime(row['trade_dttm_max']) - pd.to_datetime(row['trade_dttm_min'])).days\n",
    "        trades_per_day = total_trades / max(date_range, 1)\n",
    "        \n",
    "        # 5. POSITION SIZE RELATIVE TO VOLUME\n",
    "        # Calculate net position vs total volume for each market\n",
    "        position_ratios = []\n",
    "        for market in trader_trades['market_title'].unique():\n",
    "            market_trades = trader_trades[trader_trades['market_title'] == market]\n",
    "            \n",
    "            # Calculate net position (buys - sells) vs total volume\n",
    "            total_volume = market_trades['amount'].sum()\n",
    "            buy_volume = market_trades[market_trades['side'] == 'buy']['amount'].sum()\n",
    "            sell_volume = market_trades[market_trades['side'] == 'sell']['amount'].sum()\n",
    "            net_position = abs(buy_volume - sell_volume)\n",
    "            \n",
    "            if total_volume > 0:\n",
    "                position_ratio = net_position / total_volume\n",
    "                position_ratios.append(position_ratio)\n",
    "        \n",
    "        avg_position_ratio = np.mean(position_ratios) if position_ratios else 1\n",
    "        \n",
    "        # 6. PRICE SPREAD BEHAVIOR\n",
    "        # Look for trades at different price levels (suggesting liquidity provision)\n",
    "        price_std = row['price_std'] if not pd.isna(row['price_std']) else 0\n",
    "        price_diversity = min(price_std * 10, 1)  # Normalize to 0-1 scale\n",
    "        \n",
    "        # COMPOSITE MARKET MAKER SCORE\n",
    "        # Weight different factors\n",
    "        mm_score = (\n",
    "            min(trade_size_percentile * 0.15, 0.15) +  # Large orders (15%)\n",
    "            both_sides_score * 0.25 +                   # Both sides (25%)\n",
    "            min(market_diversification * 5, 0.20) +     # Market diversity (20%)\n",
    "            avg_outcome_balance * 0.15 +                # Outcome balance (15%)\n",
    "            min(trades_per_day / 10, 0.15) +            # Frequency (15%)\n",
    "            (1 - avg_position_ratio) * 0.10             # Low net positions (10%)\n",
    "        )\n",
    "        \n",
    "        mm_indicators.append({\n",
    "            'trader_id': trader_id,\n",
    "            'total_trades': total_trades,\n",
    "            'avg_trade_size': avg_trade_size,\n",
    "            'both_sides_score': both_sides_score,\n",
    "            'buy_ratio': buy_ratio,\n",
    "            'sell_ratio': sell_ratio,\n",
    "            'unique_markets': unique_markets,\n",
    "            'market_diversification': market_diversification,\n",
    "            'avg_outcome_balance': avg_outcome_balance,\n",
    "            'trades_per_day': trades_per_day,\n",
    "            'avg_position_ratio': avg_position_ratio,\n",
    "            'price_diversity': price_diversity,\n",
    "            'mm_score': mm_score,\n",
    "            'likely_mm': mm_score > 0.6  # Threshold for market maker classification\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(mm_indicators).sort_values('mm_score', ascending=False)\n",
    "\n",
    "def identify_market_makers(df, top_n=10):\n",
    "    \"\"\"\n",
    "    Identify top potential market makers from trade data.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Trade data\n",
    "        top_n (int): Number of top market makers to return\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Top market makers with their characteristics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure trade_dttm is datetime\n",
    "    if 'trade_dttm' in df.columns:\n",
    "        df['trade_dttm'] = pd.to_datetime(df['trade_dttm'])\n",
    "    \n",
    "    # Analyze all traders\n",
    "    mm_analysis = analyze_market_maker_characteristics(df)\n",
    "    \n",
    "    # Filter for likely market makers\n",
    "    likely_mms = mm_analysis[mm_analysis['likely_mm'] == True]\n",
    "    \n",
    "    print(f\"Found {len(likely_mms)} likely market makers out of {len(mm_analysis)} total traders\")\n",
    "    print(f\"\\nTop {top_n} Market Makers:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    top_mms = mm_analysis.head(top_n)\n",
    "    \n",
    "    for i, (_, trader) in enumerate(top_mms.iterrows(), 1):\n",
    "        print(f\"{i:2d}. Trader: {trader['trader_id'][:10]}...\")\n",
    "        print(f\"    MM Score: {trader['mm_score']:.3f}\")\n",
    "        print(f\"    Total Trades: {trader['total_trades']:,}\")\n",
    "        print(f\"    Both Sides Score: {trader['both_sides_score']:.3f} (Buy: {trader['buy_ratio']:.2%}, Sell: {trader['sell_ratio']:.2%})\")\n",
    "        print(f\"    Markets: {trader['unique_markets']}, Avg Position Ratio: {trader['avg_position_ratio']:.3f}\")\n",
    "        print(f\"    Trades/Day: {trader['trades_per_day']:.1f}\")\n",
    "        print()\n",
    "    \n",
    "    return mm_analysis\n",
    "\n",
    "# Example usage:\n",
    "# df = read_polymarket_csv('your_file.csv')\n",
    "# market_makers = identify_market_makers(df, top_n=15)\n",
    "# \n",
    "# # View detailed results\n",
    "# print(market_makers[['trader_id', 'mm_score', 'total_trades', 'both_sides_score', 'unique_markets']].head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
