{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Data Visualization for PeriodicTaskExecutor\n",
    "\n",
    "This notebook demonstrates several approaches to visualize streaming data from the PeriodicTaskExecutor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import asyncio\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom IPython.display import display, clear_output, HTML\nimport ipywidgets as widgets\nfrom collections import deque\nimport time\nimport nest_asyncio\n\n# Allow nested asyncio in Jupyter\nnest_asyncio.apply()\n\n# Import from the installed package\nfrom src.utils.periodic_task_executor import PeriodicTaskExecutor\nfrom src.models.market_probability import MarketProbability\n\n%matplotlib widget"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Mock Data Fetchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock data fetchers that simulate getting market probabilities\n",
    "request_counter = 0\n",
    "\n",
    "async def fetch_polymarket_data():\n",
    "    \"\"\"Simulate fetching Polymarket data\"\"\"\n",
    "    global request_counter\n",
    "    request_counter += 1\n",
    "    \n",
    "    # Simulate random walk for probability\n",
    "    base_prob = 0.65\n",
    "    noise = np.random.normal(0, 0.02)\n",
    "    probability = max(0.1, min(0.9, base_prob + noise))\n",
    "    \n",
    "    return MarketProbability(\n",
    "        request_id=request_counter,\n",
    "        fetched_at=datetime.utcnow(),\n",
    "        probability=probability,\n",
    "        source=\"polymarket\",\n",
    "        team=\"Team A\",\n",
    "        meta={\"volume\": np.random.randint(10000, 50000)}\n",
    "    )\n",
    "\n",
    "async def fetch_betfair_data():\n",
    "    \"\"\"Simulate fetching Betfair data\"\"\"\n",
    "    global request_counter\n",
    "    request_counter += 1\n",
    "    \n",
    "    # Simulate different probability with correlation\n",
    "    base_prob = 0.63\n",
    "    noise = np.random.normal(0, 0.015)\n",
    "    probability = max(0.1, min(0.9, base_prob + noise))\n",
    "    \n",
    "    return MarketProbability(\n",
    "        request_id=request_counter,\n",
    "        fetched_at=datetime.utcnow(),\n",
    "        probability=probability,\n",
    "        source=\"betfair\",\n",
    "        team=\"Team A\",\n",
    "        meta={\"liquidity\": np.random.randint(50000, 200000)}\n",
    "    )\n",
    "\n",
    "async def fetch_pinnacle_data():\n",
    "    \"\"\"Simulate fetching Pinnacle data\"\"\"\n",
    "    global request_counter\n",
    "    request_counter += 1\n",
    "    \n",
    "    # Simulate sharp book with less noise\n",
    "    base_prob = 0.64\n",
    "    noise = np.random.normal(0, 0.01)\n",
    "    probability = max(0.1, min(0.9, base_prob + noise))\n",
    "    \n",
    "    return MarketProbability(\n",
    "        request_id=request_counter,\n",
    "        fetched_at=datetime.utcnow(),\n",
    "        probability=probability,\n",
    "        source=\"pinnacle\",\n",
    "        team=\"Team A\",\n",
    "        meta={\"limit\": 10000}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Matplotlib Real-time Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LivePlotter:\n",
    "    def __init__(self, window_size=50):\n",
    "        self.window_size = window_size\n",
    "        self.data = {\n",
    "            'polymarket': deque(maxlen=window_size),\n",
    "            'betfair': deque(maxlen=window_size),\n",
    "            'pinnacle': deque(maxlen=window_size),\n",
    "            'timestamps': deque(maxlen=window_size)\n",
    "        }\n",
    "        \n",
    "        # Setup plot\n",
    "        self.fig, (self.ax1, self.ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "        self.lines = {}\n",
    "        \n",
    "        # Initialize lines\n",
    "        for source in ['polymarket', 'betfair', 'pinnacle']:\n",
    "            self.lines[source], = self.ax1.plot([], [], label=source, marker='o', markersize=4)\n",
    "        \n",
    "        self.ax1.set_xlabel('Time (seconds ago)')\n",
    "        self.ax1.set_ylabel('Probability')\n",
    "        self.ax1.set_title('Market Probabilities Over Time')\n",
    "        self.ax1.legend()\n",
    "        self.ax1.grid(True)\n",
    "        \n",
    "        # Setup spread plot\n",
    "        self.spread_line, = self.ax2.plot([], [], 'r-', label='Max Spread')\n",
    "        self.ax2.set_xlabel('Time (seconds ago)')\n",
    "        self.ax2.set_ylabel('Spread')\n",
    "        self.ax2.set_title('Maximum Probability Spread')\n",
    "        self.ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "    def update_data(self, results):\n",
    "        \"\"\"Update data from executor results\"\"\"\n",
    "        timestamp = datetime.utcnow()\n",
    "        self.data['timestamps'].append(timestamp)\n",
    "        \n",
    "        for source in ['polymarket', 'betfair', 'pinnacle']:\n",
    "            if source in results:\n",
    "                prob = results[source].probability\n",
    "                self.data[source].append(prob)\n",
    "            elif len(self.data[source]) > 0:\n",
    "                # Carry forward last value if missing\n",
    "                self.data[source].append(self.data[source][-1])\n",
    "    \n",
    "    def animate(self, frame):\n",
    "        \"\"\"Animation function for matplotlib\"\"\"\n",
    "        if len(self.data['timestamps']) < 2:\n",
    "            return\n",
    "        \n",
    "        # Calculate seconds ago\n",
    "        current_time = self.data['timestamps'][-1]\n",
    "        x_data = [(current_time - ts).total_seconds() for ts in self.data['timestamps']]\n",
    "        x_data = [-x for x in x_data]  # Negative to show most recent on right\n",
    "        \n",
    "        # Update probability lines\n",
    "        for source in ['polymarket', 'betfair', 'pinnacle']:\n",
    "            if len(self.data[source]) > 0:\n",
    "                self.lines[source].set_data(x_data, list(self.data[source]))\n",
    "        \n",
    "        # Calculate and plot spread\n",
    "        if all(len(self.data[s]) > 0 for s in ['polymarket', 'betfair', 'pinnacle']):\n",
    "            spreads = []\n",
    "            for i in range(len(self.data['timestamps'])):\n",
    "                probs = [self.data[s][i] for s in ['polymarket', 'betfair', 'pinnacle']]\n",
    "                spread = max(probs) - min(probs)\n",
    "                spreads.append(spread)\n",
    "            self.spread_line.set_data(x_data, spreads)\n",
    "        \n",
    "        # Adjust axes\n",
    "        if x_data:\n",
    "            self.ax1.set_xlim(min(x_data) - 1, max(x_data) + 1)\n",
    "            self.ax1.set_ylim(0.5, 0.8)\n",
    "            self.ax2.set_xlim(min(x_data) - 1, max(x_data) + 1)\n",
    "            self.ax2.set_ylim(0, 0.1)\n",
    "        \n",
    "        return list(self.lines.values()) + [self.spread_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run live plotting with PeriodicTaskExecutor\n",
    "async def run_live_plot(duration=30):\n",
    "    plotter = LivePlotter()\n",
    "    executor = PeriodicTaskExecutor(interval=2.0)\n",
    "    \n",
    "    # Add our mock fetchers\n",
    "    executor.add_task(fetch_polymarket_data, \"polymarket\")\n",
    "    executor.add_task(fetch_betfair_data, \"betfair\")\n",
    "    executor.add_task(fetch_pinnacle_data, \"pinnacle\")\n",
    "    \n",
    "    # Storage for CSV\n",
    "    all_data = []\n",
    "    \n",
    "    # Custom task to update plot\n",
    "    async def update_plot_task():\n",
    "        while True:\n",
    "            if executor.results_storage:\n",
    "                latest = executor.results_storage[-1]\n",
    "                if latest['successful_results']:\n",
    "                    plotter.update_data(latest['successful_results'])\n",
    "                    \n",
    "                    # Store for CSV\n",
    "                    for source, data in latest['successful_results'].items():\n",
    "                        all_data.append({\n",
    "                            'timestamp': data.fetched_at,\n",
    "                            'source': data.source,\n",
    "                            'team': data.team,\n",
    "                            'probability': data.probability,\n",
    "                            'request_id': data.request_id\n",
    "                        })\n",
    "            await asyncio.sleep(0.1)\n",
    "    \n",
    "    # Start animation\n",
    "    anim = FuncAnimation(plotter.fig, plotter.animate, interval=100, blit=True)\n",
    "    \n",
    "    # Run tasks\n",
    "    plot_task = asyncio.create_task(update_plot_task())\n",
    "    executor_task = asyncio.create_task(executor.start(max_batches=duration//2))\n",
    "    \n",
    "    try:\n",
    "        await executor_task\n",
    "    finally:\n",
    "        plot_task.cancel()\n",
    "        \n",
    "    # Save to CSV\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        df.to_csv('../data/live_market_probabilities.csv', index=False)\n",
    "        print(f\"\\nSaved {len(df)} records to CSV\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Uncomment to run:\n",
    "# df = await run_live_plot(duration=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Plotly Interactive Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotlyDashboard:\n",
    "    def __init__(self):\n",
    "        self.fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=('Market Probabilities', 'Probability Distribution', \n",
    "                          'Spread Over Time', 'Source Correlation'),\n",
    "            specs=[[{\"colspan\": 2}, None],\n",
    "                   [{}, {}]]\n",
    "        )\n",
    "        \n",
    "        self.data_storage = {\n",
    "            'timestamps': [],\n",
    "            'polymarket': [],\n",
    "            'betfair': [],\n",
    "            'pinnacle': []\n",
    "        }\n",
    "        \n",
    "        # Initialize traces\n",
    "        for i, source in enumerate(['polymarket', 'betfair', 'pinnacle']):\n",
    "            self.fig.add_trace(\n",
    "                go.Scatter(x=[], y=[], name=source, mode='lines+markers'),\n",
    "                row=1, col=1\n",
    "            )\n",
    "        \n",
    "        # Spread trace\n",
    "        self.fig.add_trace(\n",
    "            go.Scatter(x=[], y=[], name='Max Spread', mode='lines', \n",
    "                      line=dict(color='red')),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Layout\n",
    "        self.fig.update_layout(\n",
    "            height=800,\n",
    "            showlegend=True,\n",
    "            title_text=\"Real-time Market Probability Dashboard\"\n",
    "        )\n",
    "        \n",
    "        self.fig.update_xaxes(title_text=\"Time\", row=1, col=1)\n",
    "        self.fig.update_yaxes(title_text=\"Probability\", row=1, col=1)\n",
    "        self.fig.update_xaxes(title_text=\"Time\", row=2, col=1)\n",
    "        self.fig.update_yaxes(title_text=\"Spread\", row=2, col=1)\n",
    "        \n",
    "        self.widget = go.FigureWidget(self.fig)\n",
    "        \n",
    "    def update(self, results):\n",
    "        \"\"\"Update dashboard with new results\"\"\"\n",
    "        timestamp = datetime.utcnow()\n",
    "        self.data_storage['timestamps'].append(timestamp)\n",
    "        \n",
    "        # Update source data\n",
    "        for source in ['polymarket', 'betfair', 'pinnacle']:\n",
    "            if source in results:\n",
    "                self.data_storage[source].append(results[source].probability)\n",
    "            elif self.data_storage[source]:\n",
    "                self.data_storage[source].append(self.data_storage[source][-1])\n",
    "        \n",
    "        # Update traces\n",
    "        with self.widget.batch_update():\n",
    "            for i, source in enumerate(['polymarket', 'betfair', 'pinnacle']):\n",
    "                if self.data_storage[source]:\n",
    "                    self.widget.data[i].x = self.data_storage['timestamps']\n",
    "                    self.widget.data[i].y = self.data_storage[source]\n",
    "            \n",
    "            # Update spread\n",
    "            if all(self.data_storage[s] for s in ['polymarket', 'betfair', 'pinnacle']):\n",
    "                spreads = []\n",
    "                for i in range(len(self.data_storage['timestamps'])):\n",
    "                    probs = [self.data_storage[s][i] for s in ['polymarket', 'betfair', 'pinnacle']]\n",
    "                    spreads.append(max(probs) - min(probs))\n",
    "                \n",
    "                self.widget.data[3].x = self.data_storage['timestamps']\n",
    "                self.widget.data[3].y = spreads\n",
    "            \n",
    "            # Add histogram in subplot\n",
    "            if len(self.data_storage['timestamps']) > 5:\n",
    "                all_probs = []\n",
    "                for source in ['polymarket', 'betfair', 'pinnacle']:\n",
    "                    all_probs.extend(self.data_storage[source][-20:])\n",
    "                \n",
    "                # Clear and add histogram\n",
    "                self.widget.add_trace(\n",
    "                    go.Histogram(x=all_probs, nbinsx=20, name='Distribution'),\n",
    "                    row=2, col=2\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Plotly dashboard\n",
    "async def run_plotly_dashboard(duration=30):\n",
    "    dashboard = PlotlyDashboard()\n",
    "    display(dashboard.widget)\n",
    "    \n",
    "    executor = PeriodicTaskExecutor(interval=2.0)\n",
    "    executor.add_task(fetch_polymarket_data, \"polymarket\")\n",
    "    executor.add_task(fetch_betfair_data, \"betfair\")\n",
    "    executor.add_task(fetch_pinnacle_data, \"pinnacle\")\n",
    "    \n",
    "    async def update_dashboard():\n",
    "        while True:\n",
    "            if executor.results_storage:\n",
    "                latest = executor.results_storage[-1]\n",
    "                if latest['successful_results']:\n",
    "                    dashboard.update(latest['successful_results'])\n",
    "            await asyncio.sleep(0.5)\n",
    "    \n",
    "    update_task = asyncio.create_task(update_dashboard())\n",
    "    executor_task = asyncio.create_task(executor.start(max_batches=duration//2))\n",
    "    \n",
    "    try:\n",
    "        await executor_task\n",
    "    finally:\n",
    "        update_task.cancel()\n",
    "\n",
    "# Uncomment to run:\n",
    "# await run_plotly_dashboard(duration=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3: Simple Text-based Live Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_text_monitor(duration=20):\n",
    "    \"\"\"Simple text-based monitoring with IPython display\"\"\"\n",
    "    executor = PeriodicTaskExecutor(interval=2.0)\n",
    "    executor.add_task(fetch_polymarket_data, \"polymarket\")\n",
    "    executor.add_task(fetch_betfair_data, \"betfair\")\n",
    "    executor.add_task(fetch_pinnacle_data, \"pinnacle\")\n",
    "    \n",
    "    # Create output widget\n",
    "    output = widgets.Output()\n",
    "    display(output)\n",
    "    \n",
    "    recent_data = deque(maxlen=10)\n",
    "    \n",
    "    async def update_display():\n",
    "        while True:\n",
    "            if executor.results_storage:\n",
    "                latest = executor.results_storage[-1]\n",
    "                if latest['successful_results']:\n",
    "                    # Store data\n",
    "                    recent_data.append({\n",
    "                        'time': datetime.utcnow(),\n",
    "                        'data': latest['successful_results']\n",
    "                    })\n",
    "                    \n",
    "                    with output:\n",
    "                        clear_output(wait=True)\n",
    "                        \n",
    "                        print(\"=\" * 60)\n",
    "                        print(f\"LIVE MARKET PROBABILITIES - {datetime.utcnow().strftime('%H:%M:%S')}\")\n",
    "                        print(\"=\" * 60)\n",
    "                        \n",
    "                        # Current values\n",
    "                        print(\"\\nCurrent Values:\")\n",
    "                        for source, data in latest['successful_results'].items():\n",
    "                            print(f\"  {source:12} : {data.probability:.4f} ({data.team})\")\n",
    "                        \n",
    "                        # Calculate spread\n",
    "                        probs = [d.probability for d in latest['successful_results'].values()]\n",
    "                        if probs:\n",
    "                            spread = max(probs) - min(probs)\n",
    "                            avg_prob = sum(probs) / len(probs)\n",
    "                            print(f\"\\n  Spread       : {spread:.4f}\")\n",
    "                            print(f\"  Average      : {avg_prob:.4f}\")\n",
    "                        \n",
    "                        # Recent history\n",
    "                        print(\"\\n\\nRecent History:\")\n",
    "                        print(\"Time     | Polymarket | Betfair   | Pinnacle  | Spread\")\n",
    "                        print(\"-\" * 60)\n",
    "                        \n",
    "                        for entry in recent_data:\n",
    "                            time_str = entry['time'].strftime('%H:%M:%S')\n",
    "                            values = {}\n",
    "                            for source, data in entry['data'].items():\n",
    "                                values[source] = data.probability\n",
    "                            \n",
    "                            if values:\n",
    "                                spread = max(values.values()) - min(values.values())\n",
    "                                print(f\"{time_str} | \"\n",
    "                                      f\"{values.get('polymarket', 0):.4f}    | \"\n",
    "                                      f\"{values.get('betfair', 0):.4f}    | \"\n",
    "                                      f\"{values.get('pinnacle', 0):.4f}   | \"\n",
    "                                      f\"{spread:.4f}\")\n",
    "                        \n",
    "                        # Stats\n",
    "                        print(f\"\\n\\nStatistics:\")\n",
    "                        print(f\"  Total fetches: {len(executor.results_storage)}\")\n",
    "                        print(f\"  Errors: {executor.error_count}\")\n",
    "                        \n",
    "            await asyncio.sleep(0.5)\n",
    "    \n",
    "    update_task = asyncio.create_task(update_display())\n",
    "    executor_task = asyncio.create_task(executor.start(max_batches=duration//2))\n",
    "    \n",
    "    try:\n",
    "        await executor_task\n",
    "    finally:\n",
    "        update_task.cancel()\n",
    "\n",
    "# Uncomment to run:\n",
    "# await run_text_monitor(duration=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 4: Save to CSV and Monitor File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVMonitor:\n",
    "    def __init__(self, filename='../data/live_probabilities.csv'):\n",
    "        self.filename = filename\n",
    "        self.df = pd.DataFrame()\n",
    "        \n",
    "    def append_results(self, results):\n",
    "        \"\"\"Append results to CSV file\"\"\"\n",
    "        rows = []\n",
    "        timestamp = datetime.utcnow()\n",
    "        \n",
    "        for source, data in results.items():\n",
    "            rows.append({\n",
    "                'timestamp': timestamp,\n",
    "                'source': data.source,\n",
    "                'team': data.team,\n",
    "                'probability': data.probability,\n",
    "                'request_id': data.request_id,\n",
    "                **{f'meta_{k}': v for k, v in data.meta.items()}\n",
    "            })\n",
    "        \n",
    "        new_df = pd.DataFrame(rows)\n",
    "        \n",
    "        # Append to file\n",
    "        if not self.df.empty:\n",
    "            self.df = pd.concat([self.df, new_df], ignore_index=True)\n",
    "        else:\n",
    "            self.df = new_df\n",
    "            \n",
    "        # Save to CSV\n",
    "        self.df.to_csv(self.filename, index=False)\n",
    "        \n",
    "    def plot_from_csv(self):\n",
    "        \"\"\"Read CSV and create plots\"\"\"\n",
    "        if not self.df.empty:\n",
    "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "            \n",
    "            # Plot probabilities by source\n",
    "            for source in self.df['source'].unique():\n",
    "                source_data = self.df[self.df['source'] == source]\n",
    "                ax1.plot(source_data['timestamp'], source_data['probability'], \n",
    "                        label=source, marker='o', markersize=4)\n",
    "            \n",
    "            ax1.set_xlabel('Time')\n",
    "            ax1.set_ylabel('Probability')\n",
    "            ax1.set_title('Market Probabilities from CSV')\n",
    "            ax1.legend()\n",
    "            ax1.grid(True)\n",
    "            \n",
    "            # Calculate and plot rolling spread\n",
    "            pivot_df = self.df.pivot(index='timestamp', columns='source', values='probability')\n",
    "            pivot_df['spread'] = pivot_df.max(axis=1) - pivot_df.min(axis=1)\n",
    "            \n",
    "            ax2.plot(pivot_df.index, pivot_df['spread'], 'r-', linewidth=2)\n",
    "            ax2.set_xlabel('Time')\n",
    "            ax2.set_ylabel('Spread')\n",
    "            ax2.set_title('Probability Spread Over Time')\n",
    "            ax2.grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with CSV monitoring\n",
    "async def run_with_csv_monitor(duration=20):\n",
    "    monitor = CSVMonitor()\n",
    "    executor = PeriodicTaskExecutor(interval=2.0)\n",
    "    \n",
    "    executor.add_task(fetch_polymarket_data, \"polymarket\")\n",
    "    executor.add_task(fetch_betfair_data, \"betfair\")\n",
    "    executor.add_task(fetch_pinnacle_data, \"pinnacle\")\n",
    "    \n",
    "    async def save_to_csv():\n",
    "        while True:\n",
    "            if executor.results_storage:\n",
    "                latest = executor.results_storage[-1]\n",
    "                if latest['successful_results']:\n",
    "                    monitor.append_results(latest['successful_results'])\n",
    "            await asyncio.sleep(0.5)\n",
    "    \n",
    "    save_task = asyncio.create_task(save_to_csv())\n",
    "    executor_task = asyncio.create_task(executor.start(max_batches=duration//2))\n",
    "    \n",
    "    try:\n",
    "        await executor_task\n",
    "    finally:\n",
    "        save_task.cancel()\n",
    "    \n",
    "    print(f\"\\nData saved to {monitor.filename}\")\n",
    "    print(f\"Total records: {len(monitor.df)}\")\n",
    "    \n",
    "    # Display final plot\n",
    "    monitor.plot_from_csv()\n",
    "    \n",
    "    return monitor\n",
    "\n",
    "# Uncomment to run:\n",
    "# monitor = await run_with_csv_monitor(duration=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting real-time data collection demo...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PeriodicTaskExecutor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDemo complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Run the demo\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m quick_demo()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mquick_demo\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting real-time data collection demo...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Create executor\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m executor = \u001b[43mPeriodicTaskExecutor\u001b[49m(interval=\u001b[32m1.0\u001b[39m)\n\u001b[32m      7\u001b[39m executor.add_task(fetch_polymarket_data, \u001b[33m\"\u001b[39m\u001b[33mpolymarket\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m executor.add_task(fetch_betfair_data, \u001b[33m\"\u001b[39m\u001b[33mbetfair\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'PeriodicTaskExecutor' is not defined"
     ]
    }
   ],
   "source": [
    "# Quick example combining everything\n",
    "async def quick_demo():\n",
    "    print(\"Starting real-time data collection demo...\\n\")\n",
    "    \n",
    "    # Create executor\n",
    "    executor = PeriodicTaskExecutor(interval=1.0)\n",
    "    executor.add_task(fetch_polymarket_data, \"polymarket\")\n",
    "    executor.add_task(fetch_betfair_data, \"betfair\")\n",
    "    executor.add_task(fetch_pinnacle_data, \"pinnacle\")\n",
    "    \n",
    "    # Simple live display\n",
    "    async def display_latest():\n",
    "        for _ in range(10):\n",
    "            await asyncio.sleep(1)\n",
    "            if executor.results_storage:\n",
    "                latest = executor.results_storage[-1]\n",
    "                if latest['successful_results']:\n",
    "                    print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] Latest probabilities:\")\n",
    "                    for source, data in latest['successful_results'].items():\n",
    "                        print(f\"  {source}: {data.probability:.4f}\")\n",
    "    \n",
    "    # Run both concurrently\n",
    "    await asyncio.gather(\n",
    "        executor.start(max_batches=10),\n",
    "        display_latest()\n",
    "    )\n",
    "    \n",
    "    print(\"\\nDemo complete!\")\n",
    "\n",
    "# Run the demo\n",
    "await quick_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates several approaches for visualizing streaming data:\n",
    "\n",
    "1. **Matplotlib Animation**: Best for scientific/publication-quality plots with real-time updates\n",
    "2. **Plotly Dashboard**: Best for interactive exploration and multiple views\n",
    "3. **Text Monitor**: Best for quick debugging and terminal-style monitoring\n",
    "4. **CSV Monitor**: Best for data persistence and post-processing\n",
    "\n",
    "Choose the approach that best fits your needs. For production use, consider:\n",
    "- Using a proper time-series database instead of CSV\n",
    "- Implementing websocket connections for lower latency\n",
    "- Adding error handling and reconnection logic\n",
    "- Using a dedicated dashboard solution like Grafana for monitoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}